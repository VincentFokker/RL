{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rl.environments\n",
    "import yaml\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "import rl.helpers\n",
    "import gym\n",
    "from stable_baselines.gail import generate_expert_traj\n",
    "from stable_baselines.gail import ExpertDataset\n",
    "from stable_baselines import PPO2\n",
    "import pathlib\n",
    "from os.path import join\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines.common.callbacks import EvalCallback\n",
    "\n",
    "path = 'D:/Drive/git/RL/'\n",
    "env_name = 'ConveyorEnv'\n",
    "subdir = '20210102_1000'\n",
    "\n",
    "config_path = join(path, 'rl', 'config','{}.yml'.format(env_name))\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "env_obj = getattr(rl.environments, env_name)\n",
    "env = env_obj(config)\n",
    "\n",
    "def decode_binary(binary_array):\n",
    "    return [int(\"\".join([str(n) for n in [int(l) for l in list(binary_array[i-2:i])]]),2) for i in range(2,len(binary_array)+2,2)]\n",
    "\n",
    "def decode_action(order_type, goal):\n",
    "    return (order_type-1 )* env.amount_of_gtps + goal\n",
    "\n",
    "def dummy_expert(obs):\n",
    "    \"\"\"\n",
    "    Based on observation , heuristic determines the policy  ( can only take observation [4, 15, 16, 17, 18])\n",
    "\n",
    "    :param _obs: (np.ndarray) Current observation\n",
    "    :return: (np.ndarray) action taken by the expert\n",
    "    \"\"\"\n",
    "    threshold = 15\n",
    "    \n",
    "    demands = decode_binary(obs[:2*env.amount_of_gtps*env.in_que_observed])\n",
    "    queue_demands = [demands[i*env.in_que_observed: env.in_que_observed +i*env.in_que_observed] for i in range(env.amount_of_gtps)]\n",
    "    W_rpt = obs[2*env.amount_of_gtps*env.in_que_observed:2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps]\n",
    "    max_time_w = 6 if env.amount_of_outputs==1 else 30 if env.amount_of_outputs==2 else 60\n",
    "    W_rpt = W_rpt * max_time_w\n",
    "    \n",
    "    \n",
    "    Q_rpt = obs[2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps:2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps*2]\n",
    "    max_time_q = max_time_w*env.gtp_buffer_length\n",
    "    Q_rpt = Q_rpt * max_time_q\n",
    "    \n",
    "    P_rpt = obs[2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps*2:2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps*3]\n",
    "    P_rpt = P_rpt*env.pipeline_length\n",
    "    \n",
    "    in_pipe = obs[2 * env.amount_of_gtps * env.in_que_observed + env.amount_of_gtps * 3:2 * env.amount_of_gtps * env.in_que_observed + env.amount_of_gtps * 4]\n",
    "    #in_pipe = obs[-env.amount_of_gtps:]\n",
    "    in_pipe = in_pipe*env.pipeline_length\n",
    "    in_pipe = in_pipe.astype(int)\n",
    "    \n",
    "    actions_list = []\n",
    "    for workstation in range(env.amount_of_gtps)[::-1]:\n",
    "        total_rpt = W_rpt[workstation] + Q_rpt[workstation] + P_rpt[workstation]\n",
    "        total_pipe = env.pipeline_length + env.gtp_buffer_length + workstation * 4 + 2\n",
    "        \n",
    "        if total_rpt - total_pipe < threshold:\n",
    "            try:\n",
    "                current_demand = queue_demands[workstation][in_pipe[workstation]]\n",
    "                actions_list.append((current_demand, workstation + 1))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    try:\n",
    "        order_type, goal = actions_list[0]\n",
    "        actions_list = actions_list[1:]\n",
    "\n",
    "    except:\n",
    "        order_type, goal = 0, 0\n",
    "    \n",
    "    if order_type ==0 and goal == 0:\n",
    "        action = 0\n",
    "        \n",
    "    else:\n",
    "        action = decode_action(order_type, goal)\n",
    "\n",
    "    \n",
    "    return action\n",
    "\n",
    "## Generate Data based on heuristic for pre-training\n",
    "# Data will be saved in a numpy archive named `heuristic_expert.npz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:     1, steps:   0, R: 0.000\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "       1.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.05714286, 0.05714286, 3.6       ,\n",
       "       1.2       , 0.2       , 0.2       , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.28571429, 0.28571429, 0.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "{0: 0, 1: 0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dummy_expert(env.make_observation()))\n",
    "env.step(dummy_expert(env.make_observation()))\n",
    "print(env.idle_times_operator)\n",
    "env.render_plt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions (71552, 1)1483, R: 0.0000\n",
      "obs (71552, 28)\n",
      "rewards (71552,)\n",
      "episode_returns (50,)\n",
      "episode_starts (71552,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'actions': array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]), 'obs': array([[1., 0., 1., ..., 6., 2., 1.],\n",
       "        [1., 0., 1., ..., 6., 1., 1.],\n",
       "        [1., 0., 1., ..., 6., 1., 1.],\n",
       "        ...,\n",
       "        [0., 1., 1., ..., 6., 0., 1.],\n",
       "        [0., 1., 1., ..., 6., 0., 1.],\n",
       "        [0., 1., 1., ..., 6., 0., 1.]]), 'rewards': array([10.,  0.,  0., ...,  0.,  0.,  0.]), 'episode_returns': array([ 365.,  535.,  520.,  810.,  525.,  420.,  285., -130.,  425.,\n",
       "         650.,  370.,  520.,  520.,  965.,  430.,  365.,  590.,  570.,\n",
       "         405.,  620.,  475.,  530.,  520.,  470.,  535.,  840.,  370.,\n",
       "         530.,  580.,  330.,  490.,   35.,  465.,  250.,  515.,  365.,\n",
       "         635.,  240.,  515.,  410.,  555.,  795.,  335.,  620.,  675.,\n",
       "         630.,  720.,  445.,  650.,  485.]), 'episode_starts': array([ True, False, False, ..., False, False, False])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generate Data based on heuristic for pre-training\n",
    "# Data will be saved in a numpy archive named `heuristic_expert.npz`\n",
    "env.reset()\n",
    "generate_expert_traj(dummy_expert, 'heuristic_expert', env, n_episodes=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "th_new-venv",
   "language": "python",
   "name": "th_new-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
